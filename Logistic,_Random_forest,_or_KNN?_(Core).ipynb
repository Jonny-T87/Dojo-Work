{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic, Random forest, or KNN? (Core).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1sP9xIGKvj4fR7-Ei7KiLCHnKAfgicxaF",
      "authorship_tag": "ABX9TyPraWtqixkDsPx1B7OJGoPg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jonny-T87/Dojo-Work/blob/main/Logistic%2C_Random_forest%2C_or_KNN%3F_(Core).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic, Random forest, or KNN? (Core)\n",
        "\n",
        "Jonny Tesfahun\n",
        "-07/06/22"
      ],
      "metadata": {
        "id": "ei97DA_7Mqtm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "Hv6pava9Mp3M"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/DojoBootCamp/Project Files/wisconsinBreastCancer - wisconsinBreastCancer.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "tR2tnsaGwaWz",
        "outputId": "d99cdec8-93b8-4b2f-ada0-599802982240"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
              "0  ...         25.38          17.33           184.60      2019.0   \n",
              "1  ...         24.99          23.41           158.80      1956.0   \n",
              "2  ...         23.57          25.53           152.50      1709.0   \n",
              "3  ...         14.91          26.50            98.87       567.7   \n",
              "4  ...         22.54          16.67           152.20      1575.0   \n",
              "\n",
              "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
              "0            0.1622             0.6656           0.7119                0.2654   \n",
              "1            0.1238             0.1866           0.2416                0.1860   \n",
              "2            0.1444             0.4245           0.4504                0.2430   \n",
              "3            0.2098             0.8663           0.6869                0.2575   \n",
              "4            0.1374             0.2050           0.4000                0.1625   \n",
              "\n",
              "   symmetry_worst  fractal_dimension_worst  \n",
              "0          0.4601                  0.11890  \n",
              "1          0.2750                  0.08902  \n",
              "2          0.3613                  0.08758  \n",
              "3          0.6638                  0.17300  \n",
              "4          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41c706f1-1e26-47fa-a019-5cdf1a107baf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41c706f1-1e26-47fa-a019-5cdf1a107baf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41c706f1-1e26-47fa-a019-5cdf1a107baf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41c706f1-1e26-47fa-a019-5cdf1a107baf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning & Analyzing data:"
      ],
      "metadata": {
        "id": "QCqILUlACsGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ji5UXxMwsE_",
        "outputId": "dc6c4d8d-0186-48f5-de0b-eaa9443232e9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                         0\n",
              "diagnosis                  0\n",
              "radius_mean                0\n",
              "texture_mean               0\n",
              "perimeter_mean             0\n",
              "area_mean                  0\n",
              "smoothness_mean            0\n",
              "compactness_mean           0\n",
              "concavity_mean             0\n",
              "concave points_mean        0\n",
              "symmetry_mean              0\n",
              "fractal_dimension_mean     0\n",
              "radius_se                  0\n",
              "texture_se                 0\n",
              "perimeter_se               0\n",
              "area_se                    0\n",
              "smoothness_se              0\n",
              "compactness_se             0\n",
              "concavity_se               0\n",
              "concave points_se          0\n",
              "symmetry_se                0\n",
              "fractal_dimension_se       0\n",
              "radius_worst               0\n",
              "texture_worst              0\n",
              "perimeter_worst            0\n",
              "area_worst                 0\n",
              "smoothness_worst           0\n",
              "compactness_worst          0\n",
              "concavity_worst            0\n",
              "concave points_worst       0\n",
              "symmetry_worst             0\n",
              "fractal_dimension_worst    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4gMFVXKw3mj",
        "outputId": "a9c65d0f-433d-4ef5-f772-b3ff3bbbbb8d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting diagnosis from object to numbers\n",
        "df['diagnosis'] = df['diagnosis'].replace({'B':0, 'M':1})"
      ],
      "metadata": {
        "id": "K-ZgMZ_Yw8rc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ploting diagnosis B & A\n",
        "plt.scatter(df['concave points_worst'], df['diagnosis'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "gEPForDmxXuB",
        "outputId": "4bcd38e7-82a0-4ead-9b09-f23c054e1bdc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6b84505690>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAR+0lEQVR4nO3df4wcZ33H8ff3zufkkgIO9SE1Zyc2kgl1+KGUbUBF5YcAxUmLnUJS7CoS0AiLQmglkKVEQSlNVUGxWjVSU9G0QhSkxgSKLFeYWhRMq1ZN6jPOj9rB4JhQ+4LgSOK0YIMv52//2D2zPu/5Zm/3bveevl+SdTPPPDPzfXZmP7femb2NzESSVKaBXhcgSVo4hrwkFcyQl6SCGfKSVDBDXpIKtqxXO165cmWuWbOmV7uXpCVp//79P8rMkar9exbya9asYWxsrFe7l6QlKSK+105/366RpIIZ8pJUMENekgpmyEtSwQx5SSrYnHfXRMSngd8EfpiZr2ixPIB7gBuAk8B7MvOb3S6013YeGGf7nsM8deIUl68YZtt1V3HjNaO9LmvWutqpd2bfN798hL3fmmD8xCkGI5jKZPQC7c3bbrVf4Ly2se89w/0PHWOqxR/Iu+ySITLhxKnJs20BDA4Ez5/Jc9oSztYwvZ/xE6fOLpu2fDA4PXXuvgJ4yQuW84P/Pd3uw953BgJeePHQOY/ZYmr1+M6m1TnzsV0Hz9be6thNTuXZtuWDQWYyeaZabUMDcOlF9cdm+rxdMTxEBDx7cpKBgOnTamgApvLn88DZvidOTvKipun5PK++/Oj3efbk5Nntfmzj1QueIzHXX6GMiDcAPwY+O0vI3wB8iHrIvxa4JzNfO9eOa7VaLpVbKHceGOeOLz3Gqcmps23DQ4N8/B2v7GnQz1bXO18zyj/sH69Ub6tttGt628B52xoaCAiYbAqAwYFg6kx3//ppq/2ofzWfM9u+8AiTXT4fFkunz6uhgWD7za9uK0ciYn9m1qr2n/Ptmsz8V+CZC3TZRP0XQGbmg8CKiPilqgUsBdv3HD7vYJ2anGL7nsM9qqhutrruf+hY5XpbbaNd09tuta3JM3le8HY74Gfbj/pX8zmzVAMeOn9eTZ7JBc+RbnwYahQ41jR/vNH2/ZkdI2IrsBXgiiuu6MKuF8dTJ0611b5YZtt/q7dAZuvfrTH0+rHQ0lPKOdPp82qhH4dFvfCamfdlZi0zayMjlT+V23OXrxhuq32xzLb/wYjK/bs1hstXDPf88dDSUso50+nzaqEfg26E/Diwuml+VaOtGNuuu4rhocFz2oaHBs9e7OuV2era8trVletttY12TW+71baGBoKhwXN/6QwOtP4l1IlW+1H/aj5nhhbgfFgsnT6vhgZiwXOkG2/X7AJui4gd1C+8PpeZ571Vs5RNXxTpt7trLlRX7coXV6q31TY6ubumVT2t2ry7pruW8t01QHF318z2vOrXu2vuB94ErAR+APwhMASQmZ9q3EL5l8AG6rdQvjcz57xtZindXSNJ/aLdu2vmfCWfmVvmWJ7AB6vuUJK0ePzEqyQVzJCXpIIZ8pJUMENekgpmyEtSwQx5SSqYIS9JBTPkJalghrwkFcyQl6SCGfKSVDBDXpIKZshLUsEMeUkqmCEvSQUz5CWpYIa8JBXMkJekghnyklQwQ16SCmbIS1LBDHlJKpghL0kFM+QlqWCGvCQVzJCXpIIZ8pJUMENekgpmyEtSwQx5SSqYIS9JBasU8hGxISIOR8SRiLi9xfIrImJvRByIiEcj4obulypJatecIR8Rg8C9wPXAemBLRKyf0e2jwAOZeQ2wGfirbhcqSWpflVfy1wJHMvNoZp4GdgCbZvRJ4IWN6RcBT3WvREnSfFUJ+VHgWNP88UZbs48Bt0TEcWA38KFWG4qIrRExFhFjExMT8yhXktSObl143QJ8JjNXATcAn4uI87admfdlZi0zayMjI13atSRpNlVCfhxY3TS/qtHW7FbgAYDM/A/gYmBlNwqUJM1flZDfB6yLiLURsZz6hdVdM/r8N/AWgIj4Zeoh7/sxktRjc4Z8Zj4P3AbsAR6nfhfNwYi4OyI2Nrp9BHhfRDwC3A+8JzNzoYqWJFWzrEqnzNxN/YJqc9tdTdOHgNd3tzRJUqf8xKskFcyQl6SCGfKSVDBDXpIKZshLUsEMeUkqmCEvSQUz5CWpYIa8JBXMkJekghnyklQwQ16SCmbIS1LBDHlJKpghL0kFM+QlqWCGvCQVzJCXpIIZ8pJUMENekgpmyEtSwQx5SSqYIS9JBTPkJalghrwkFcyQl6SCGfKSVDBDXpIKZshLUsEMeUkqWKWQj4gNEXE4Io5ExO2z9PntiDgUEQcj4u+7W6YkaT6WzdUhIgaBe4G3AceBfRGxKzMPNfVZB9wBvD4zn42IlyxUwZKk6qq8kr8WOJKZRzPzNLAD2DSjz/uAezPzWYDM/GF3y5QkzUeVkB8FjjXNH2+0NXsZ8LKI+PeIeDAiNrTaUERsjYixiBibmJiYX8WSpMq6deF1GbAOeBOwBfibiFgxs1Nm3peZtcysjYyMdGnXkqTZVAn5cWB10/yqRluz48CuzJzMzO8C36Ye+pKkHqoS8vuAdRGxNiKWA5uBXTP67KT+Kp6IWEn97ZujXaxTkjQPc4Z8Zj4P3AbsAR4HHsjMgxFxd0RsbHTbAzwdEYeAvcC2zHx6oYqWJFUTmdmTHddqtRwbG+vJviVpqYqI/ZlZq9rfT7xKUsEMeUkqmCEvSQUz5CWpYIa8JBXMkJekghnyklQwQ16SCmbIS1LBDHlJKpghL0kFM+QlqWCGvCQVzJCXpIIZ8pJUMENekgpmyEtSwQx5SSqYIS9JBTPkJalghrwkFcyQl6SCGfKSVDBDXpIKZshLUsEMeUkqmCEvSQUz5CWpYIa8JBXMkJekghnyklSwSiEfERsi4nBEHImI2y/Q750RkRFR616JkqT5mjPkI2IQuBe4HlgPbImI9S36vQD4A+ChbhcpSZqfKq/krwWOZObRzDwN7AA2tej3x8CfAj/tYn2SpA5UCflR4FjT/PFG21kR8SvA6sz88oU2FBFbI2IsIsYmJibaLlaS1J6OL7xGxADw58BH5uqbmfdlZi0zayMjI53uWpI0hyohPw6sbppf1Wib9gLgFcA3IuJJ4HXALi++SlLvVQn5fcC6iFgbEcuBzcCu6YWZ+VxmrszMNZm5BngQ2JiZYwtSsSSpsjlDPjOfB24D9gCPAw9k5sGIuDsiNi50gZKk+VtWpVNm7gZ2z2i7a5a+b+q8LElSN/iJV0kqmCEvSQUz5CWpYIa8JBXMkJekghnyklQwQ16SCmbIS1LBDHlJKpghL0kFM+QlqWCGvCQVzJCXpIIZ8pJUMENekgpmyEtSwQx5SSqYIS9JBTPkJalghrwkFcyQl6SCGfKSVDBDXpIKZshLUsEMeUkqmCEvSQUz5CWpYIa8JBXMkJekghnyklSwSiEfERsi4nBEHImI21ss/3BEHIqIRyPiaxFxZfdLlSS1a86Qj4hB4F7gemA9sCUi1s/odgCoZeargC8Cn+x2oZKk9lV5JX8tcCQzj2bmaWAHsKm5Q2buzcyTjdkHgVXdLVOSNB9VQn4UONY0f7zRNptbga+0WhARWyNiLCLGJiYmqlcpSZqXrl54jYhbgBqwvdXyzLwvM2uZWRsZGenmriVJLSyr0GccWN00v6rRdo6IeCtwJ/DGzPxZd8qTJHWiyiv5fcC6iFgbEcuBzcCu5g4RcQ3w18DGzPxh98uUJM3HnCGfmc8DtwF7gMeBBzLzYETcHREbG922A78AfCEiHo6IXbNsTpK0iKq8XUNm7gZ2z2i7q2n6rV2uS5LUBX7iVZIKZshLUsEMeUkqmCEvSQUz5CWpYIa8JBXMkJekghnyklQwQ16SCmbIS1LBDHlJKpghL0kFM+QlqWCGvCQVzJCXpIIZ8pJUMENekgpmyEtSwQx5SSqYIS9JBTPkJalghrwkFcyQl6SCGfKSVDBDXpIKZshLUsEMeUkqmCEvSQUz5CWpYIa8JBXMkJekgi2r0ikiNgD3AIPA32bmJ2Ysvwj4LPAa4GngXZn5ZHdLhTW3f/m8tic/8RvnzO88MM4f/eNBnj05eV7fS5cP8pPTU0RAZrer00IIoJeHajCCqcyzP0dXDLPtuqsAzjvPLhkaYPmyQZ47NcnljX43XjPacrs7D4yzfc9hnjpxistXDPPml4+w91sTZ+cvtK7Ujsg50i4iBoFvA28DjgP7gC2ZeaipzweAV2Xm+yNiM/BbmfmuC223Vqvl2NhY5UJbBfy06aDfeWCcbV98hMkpE1wLZ2ggOANMnbnweTY8NMjH3/HK88J654Fx7vjSY5yanGp7XSki9mdmrWr/Km/XXAscycyjmXka2AFsmtFnE/B3jekvAm+JiKhaRLds33PYgNeCmzyTcwY8wKnJKbbvOXxe+/Y9hy8Y8BdaV2pXlZAfBY41zR9vtLXsk5nPA88BvzhzQxGxNSLGImJsYmJifhVfwFMnTnV9m1InWp2TVc9Tz2d1w6JeeM3M+zKzlpm1kZGRrm//8hXDXd+m1IlW52TV89TzWd1QJeTHgdVN86sabS37RMQy4EXUL8Auqm3XXcXQ4KK/S6T/Z4YGgsGBuc+z4aHBsxdpm2277iqGhwbnta7Uriohvw9YFxFrI2I5sBnYNaPPLuDdjembgK/nXFd02zTzLppW7TdeM8r2m17NZZcMtex76fL6E2vxrxZovnp9qAYbJ8v0z9EVw2y/+dX82c3nn2eXDA2wYniIaPSb7cLpjdeM8vF3vJLRFcNn+97yuivOmfeiq7plzrtrACLiBuAvqN9C+enM/JOIuBsYy8xdEXEx8DngGuAZYHNmHr3QNtu9u0aS1P7dNZXuk8/M3cDuGW13NU3/FLi56k4lSYvDT7xKUsEMeUkqmCEvSQUz5CWpYJXurlmQHUdMAN+b5+orgR91sZx+UNqYHE9/K208UN6YZhvPlZlZ+dOkPQv5TkTEWDu3EC0FpY3J8fS30sYD5Y2pW+Px7RpJKpghL0kFW6ohf1+vC1gApY3J8fS30sYD5Y2pK+NZku/JS5KqWaqv5CVJFRjyklSwvgv5iNgQEYcj4khE3N5i+UUR8fnG8ociYk3Tsjsa7Ycj4rrFrHs28x1PRKyJiFMR8XDj36cWu/ZWKoznDRHxzYh4PiJumrHs3RHxnca/d89ct1c6HNNU0zGa+Se4e6LCeD4cEYci4tGI+FpEXNm0rO+OUYfj6bvjA5XG9P6IeKxR979FxPqmZe3lXGb2zT/qf8r4CeClwHLgEWD9jD4fAD7VmN4MfL4xvb7R/yJgbWM7g0t4PGuA/+r1MZnHeNYArwI+C9zU1P5i4Gjj52WN6cuW8pgay37c6zHMYzxvBi5pTP9e0znXd8eok/H04/FpY0wvbJreCPxTY7rtnOu3V/KdfGn4JmBHZv4sM78LHGlsr5eWzJegVzTneDLzycx8FDgzY93rgK9m5jOZ+SzwVWDDYhQ9h07G1I+qjGdvZp5szD5I/dveoD+PUSfj6VdVxvQ/TbOXAtN3yLSdc/0W8p18aXiVdRdbp1+CvjYiDkTEv0TEry90sRV08hj34/GBzuu6uPHl9A9GxI3dLW1e2h3PrcBX5rnuYuhkPNB/xwcqjikiPhgRTwCfBH6/nXWbVfrSEPXE94ErMvPpiHgNsDMirp7xG169d2VmjkfES4GvR8RjmflEr4uqIiJuAWrAG3tdSzfMMp4le3wy817g3oj4HeCj/PwrVtvSb6/kO/nS8CrrLrZ5j6fx37GnATJzP/X33l624BVfWCePcT8eH+iwrswcb/w8CnyD+ldg9lKl8UTEW4E7gY2Z+bN21l1knYynH48PtP847wCm/xfS/jHq9UWIGRcbllG/2LOWn1+QuHpGnw9y7oXKBxrTV3PuBYmj9P7CayfjGZmun/oFmnHgxf0+nqa+n+H8C6/fpX5B77LGdE/H04UxXQZc1JheCXyHGRfQ+nE81IPuCWDdjPa+O0Ydjqfvjk8bY1rXNP126t+nPa+c6+lgZ3kAbgC+3Thodzba7qb+GxrgYuAL1C84/Cfw0qZ172ysdxi4vtdj6WQ8wDuBg8DDwDeBt/d6LBXH86vU3yf8CfX/YR1sWvd3G+M8Ary312PpdEzArwGPNZ50jwG39nosFcfzz8APGufWw8Cufj5G8x1Pvx6fimO6p+n5v5emXwLt5px/1kCSCtZv78lLkrrIkJekghnyklQwQ16SCmbIS1LBDHlJKpghL0kF+z9WUZwFv2W2XAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting target and matrix\n",
        "X = df.drop(columns=['diagnosis', 'id'])\n",
        "y = df['diagnosis']"
      ],
      "metadata": {
        "id": "Z6ATKQ67yUB9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split data with random 42\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "id": "M_KWulSPyp6r"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression:"
      ],
      "metadata": {
        "id": "ypZLHprJOwjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making instance of the logistic regression model, scaler and making pipeline\n",
        "log_reg = LogisticRegression()\n",
        "scaler = StandardScaler()\n",
        "log_reg_pip = make_pipeline(scaler, log_reg)"
      ],
      "metadata": {
        "id": "jqwwudXfzK-b"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fiting model\n",
        "log_reg_pip.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzUXRfnt17c9",
        "outputId": "272c6634-17d4-4761-c36a-f50c2782d0e3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('logisticregression', LogisticRegression())])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking default model prediction scores, without regularization strength\n",
        "print(log_reg_pip.score(X_train, y_train))\n",
        "print(log_reg_pip.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofpBOJzy3wFg",
        "outputId": "37c1f8d6-a29a-4940-be8c-97344a49b53f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9859154929577465\n",
            "0.9790209790209791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 Tuning:"
      ],
      "metadata": {
        "id": "qwuBIx-p5-3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating regularization strength list, and list for train & test scores\n",
        "c_values = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "train_scores = []\n",
        "test_scores = []"
      ],
      "metadata": {
        "id": "kpLV2tEL6BvC"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making iterative over the c values with solver 'saga' and penalty 'l1' and max 1000, random_state 5\n",
        "for c in c_values:\n",
        "  log_reg_l1 = LogisticRegression(C=c, max_iter=1000, solver='saga', random_state=5, penalty='l1')\n",
        "  log_reg_pip_l1 = make_pipeline(scaler, log_reg_l1)\n",
        "  log_reg_pip_l1.fit(X_train, y_train)\n",
        "\n",
        "  train_scores.append(log_reg_pip_l1.score(X_train, y_train))\n",
        "  test_scores.append(log_reg_pip_l1.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ovao2x26o01",
        "outputId": "9495c051-0828-4625-852a-768f72522eab"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Looking at score to see which is better prediction, looks like it is c=1\n",
        "{c:score for c, score in zip(c_values, test_scores)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snkwDqUZ85yw",
        "outputId": "a36c7b80-953f-4ea7-b398-a9260ca777ac"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0001: 0.6223776223776224,\n",
              " 0.001: 0.6223776223776224,\n",
              " 0.01: 0.951048951048951,\n",
              " 0.1: 0.972027972027972,\n",
              " 1: 0.9790209790209791,\n",
              " 10: 0.9440559440559441,\n",
              " 100: 0.9370629370629371,\n",
              " 1000: 0.9370629370629371}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 tuning:"
      ],
      "metadata": {
        "id": "4ag-dccX_FSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating regularization strength list, and list for train & test scores for L2\n",
        "c_values_l2 = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "train_scores_l2 = []\n",
        "test_scores_l2 = []"
      ],
      "metadata": {
        "id": "Hjd5tTx-_Ijb"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making iterative over the c values with solver 'saga' and penalty 'l1' and max 1000, random_state 5\n",
        "#using 'saga' because handles multiclass problems and uses l1 & l2 penalties\n",
        "for c in c_values_l2:\n",
        "  log_reg_l2 = LogisticRegression(C=c, max_iter=1000, solver='saga', random_state=5, penalty='l2')\n",
        "  log_reg_pip_l2 = make_pipeline(scaler, log_reg_l2)\n",
        "  log_reg_pip_l2.fit(X_train, y_train)\n",
        "\n",
        "  train_scores_l2.append(log_reg_pip_l2.score(X_train, y_train))\n",
        "  test_scores_l2.append(log_reg_pip_l2.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnfUVXm4_wKZ",
        "outputId": "d93ada58-7ee1-4f7b-e323-01efc33debb2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checkingt score to see which is better prediction, looks like it is c=0.1\n",
        "{c:score for c, score in zip(c_values_l2, test_scores_l2)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YPPJR6EAyye",
        "outputId": "e0ae0d79-5bf5-430d-cc7f-24030eafa6c7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0001: 0.6433566433566433,\n",
              " 0.001: 0.9020979020979021,\n",
              " 0.01: 0.972027972027972,\n",
              " 0.1: 0.986013986013986,\n",
              " 1: 0.9790209790209791,\n",
              " 10: 0.972027972027972,\n",
              " 100: 0.972027972027972,\n",
              " 1000: 0.972027972027972}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbors:"
      ],
      "metadata": {
        "id": "rKsds7AyCeX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using k nearest neighbors with n_neighbors 9, distance as weight, and leaf_size 20\n",
        "knn = KNeighborsClassifier(n_neighbors=9, weights='distance', leaf_size=10)"
      ],
      "metadata": {
        "id": "ya4JDLqiCjsv"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making pip with knn classifier\n",
        "knn_pipe = make_pipeline(scaler, knn)\n",
        "knn_pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57xjgsCHKj0z",
        "outputId": "a6e6f1d7-6b09-480b-cd7b-c8b3cf5d0ca1"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('kneighborsclassifier',\n",
              "                 KNeighborsClassifier(leaf_size=10, n_neighbors=9,\n",
              "                                      weights='distance'))])"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making prediction using pipe\n",
        "prediction = knn_pipe.predict(X_test)\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2Rcx9mOKt8F",
        "outputId": "7f49476a-6929-4d92-fba8-d77c68f37ffb"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accy_score = knn_pipe.score(X_test, y_test)\n",
        "accy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl82NVb6LNms",
        "outputId": "ea606e19-59bd-4a60-9e06-ba621234a39d"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.972027972027972"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest:"
      ],
      "metadata": {
        "id": "Fd5k03WQOjqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf.get_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWNGxHMOPpQl",
        "outputId": "50d0b9af-8985-4e8f-ca0e-3039a0290a29"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'ccp_alpha': 0.0,\n",
              " 'criterion': 'squared_error',\n",
              " 'max_depth': None,\n",
              " 'max_features': 'auto',\n",
              " 'max_leaf_nodes': None,\n",
              " 'max_samples': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 100,\n",
              " 'n_jobs': None,\n",
              " 'oob_score': False,\n",
              " 'random_state': 42,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making instance of random forest model with n estimator 150, max depth 3\n",
        "rf = RandomForestRegressor(random_state = 42, n_estimators=150, max_depth=3)"
      ],
      "metadata": {
        "id": "9N_ZA7H6PdrH"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting model\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLL-wRMaQJQk",
        "outputId": "c9541cab-baf9-4e2d-b4a3-2280388aa9a0"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_depth=3, n_estimators=150, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the x_test\n",
        "rf.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqWCw-BaQTXD",
        "outputId": "2c456d7d-95e8-4c8d-a1bc-1a144deaf698"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01278975, 0.99399516, 0.99399516, 0.01278975, 0.01278975,\n",
              "       0.99399516, 0.99399516, 0.81624474, 0.84803878, 0.02487194,\n",
              "       0.03705243, 0.99343812, 0.04452438, 0.88993112, 0.01935424,\n",
              "       0.98080677, 0.02735043, 0.01278975, 0.01278975, 0.99399516,\n",
              "       0.1738498 , 0.01278975, 0.99399516, 0.01278975, 0.02278415,\n",
              "       0.05143695, 0.01278975, 0.03705243, 0.01278975, 0.99399516,\n",
              "       0.01591655, 0.01278975, 0.24251058, 0.02689248, 0.01278975,\n",
              "       0.01278975, 0.71651932, 0.02618001, 0.99399516, 0.04648066,\n",
              "       0.01278975, 0.99399516, 0.01278975, 0.01278975, 0.23102194,\n",
              "       0.01278975, 0.12629754, 0.04223761, 0.01278975, 0.01278975,\n",
              "       0.98732849, 0.99399516, 0.12834573, 0.12258927, 0.01278975,\n",
              "       0.01935424, 0.01278975, 0.99399516, 0.88973884, 0.01278975,\n",
              "       0.01278975, 0.99399516, 0.99399516, 0.02278415, 0.01278975,\n",
              "       0.02788402, 0.99399516, 0.98293236, 0.01278975, 0.02553703,\n",
              "       0.95026503, 0.99399516, 0.01278975, 0.99399516, 0.02278415,\n",
              "       0.09047423, 0.01278975, 0.38305516, 0.01278975, 0.1619268 ,\n",
              "       0.97038171, 0.01278975, 0.12949601, 0.99399516, 0.83569593,\n",
              "       0.98072031, 0.91038683, 0.98075775, 0.027938  , 0.01278975,\n",
              "       0.01278975, 0.31166954, 0.32531775, 0.06990765, 0.01278975,\n",
              "       0.01278975, 0.99399516, 0.99399516, 0.01278975, 0.99031869,\n",
              "       0.961082  , 0.01278975, 0.92731363, 0.99399516, 0.03159304,\n",
              "       0.01278975, 0.01591655, 0.99399516, 0.68668554, 0.06208845,\n",
              "       0.99399516, 0.01278975, 0.0654221 , 0.99399516, 0.33118221,\n",
              "       0.99399516, 0.01278975, 0.03705243, 0.04239244, 0.99399516,\n",
              "       0.45369693, 0.01278975, 0.01278975, 0.99399516, 0.02101642,\n",
              "       0.99399516, 0.99399516, 0.01278975, 0.01278975, 0.99399516,\n",
              "       0.79793731, 0.99399516, 0.05087401, 0.0322037 , 0.34854612,\n",
              "       0.83967191, 0.60622077, 0.01278975, 0.38855954, 0.95749328,\n",
              "       0.01278975, 0.99399516, 0.01278975])"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking modle performance on tes data\n",
        "\n",
        "rf_train_score = rf.score(X_train, y_train)\n",
        "rf_test_score = rf.score(X_test, y_test)\n",
        "\n",
        "print(f\"train score: {rf_train_score}\")\n",
        "print(f\"test score: {rf_test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96b4-IGrQnKM",
        "outputId": "9442eaad-4f59-492c-d927-44d883672711"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train score: 0.9304645163274312\n",
            "test score: 0.8611527523648844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Which hyperparameters did you tune for each of the models? "
      ],
      "metadata": {
        "id": "fQQ_eO4PS4R9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For Logistic Regression l1 and l2 models, the hyperparameters I tuned included c (regularization strength), max_iter, and solver. I picked regularization strength between 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, and 1000. And later picked the one with highest accuracy. Max_iter i kept at 1000 to keep consistency. I used solver='saga' because it worked with both l1 and l2 penalties, as well as it worked well with multiclass problems. \n",
        "\n",
        "- For K-Nearest Neighbors, the hyperparameters I tuned included n_neighbors, weights, and leaf_size. N_neighbors = 9 provided the highest accuracy and that is why that was used. Weight was made 'distance', because I wanted the closer neighbors of a query point to have a greater influence than neighbors which are further away. Leaf_size was made 10 just to test its impact on the model.\n",
        "\n",
        "- For Random Forest Regressor,  the hyperparameters I tuned included n_estimators and max_depth. I made n_estimator=150 b/c i wanted a little more than the default 100. I made the max_depth = 3 so that there were 3 numbers of levels in each decision tree.\n"
      ],
      "metadata": {
        "id": "wXC2LXcQS7tY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Which model would you put into production to diagnose malignant tumors?\n",
        "\n",
        "- The model that I would put into production to diagnose malignant tumors would be the L2 Logistic Regression. The main reason is due to its high accuracy of 98.6% when c=0.1. The other reason would be that it handled the high correlation between features well, filtering out noise from data, and preventing overfitting better also."
      ],
      "metadata": {
        "id": "gWARrLwbXyIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. How does consideration of the meaning of false positive and false negative errors affect how you determine what 'best' means in this case?\n",
        "\n",
        "- Well, the best in this case is a false positive. The case being that someone being misdiagnosed and having not needed treatment is less worse than someone dying from treatment never given when it was supposed to be. Thus, false positives are the lesser of two evils between false negatives."
      ],
      "metadata": {
        "id": "9bC0mE7BZHPA"
      }
    }
  ]
}